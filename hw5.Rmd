---
title: "Homework 5"
author: "Noah Johnson"
date: "March 11, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy=TRUE)

library(install.load)
install_load('tidyverse')
```

## BYSH 4.15.1 Conceptual Exercise 5 
__Why is the log of means, log($\bar{Y}$), not $\bar{Y}$, plotted against X when assessing the assumptions for Poisson regression?__  

Because Poisson regression assumes that $log(\lambda_X)$ is linear in $X$. To test this assumption empirically, we estimate $log(\lambda_X)$ at each X by finding $log(\bar{Y})$. Then we plot these estimates against X looking for a linear relationship.

## BYSH 4.15.1 Conceptual Exercise 8 (Fish)
__A state wildlife biologist collected data from 250 park visitors as they left at the end of their stay. Each were asked to report the number of fish they caught during their one week stay. On average visitors caught 21.5 fish per week.__  

__(a) Define the response. __  

We should model the response $Y$ as a Poisson random variable, representing the number of fish a park visitor catches during one week.

__(b) What are the possible values for the response? __  

As with all Poisson variables, the set of possible outcomes is $\{0, 1, 2, \dots\}$.

__(c) What does $\lambda$ represent? __

$\lambda = 21.5$ represents $E[Y]$, the average number of fish a park visitor catches per week.

__(d) Would a zero-inflated model be considered here? If so, what would be a "true zero?"__

We should consider a zero-inflated model if during the process of exploratory data analysis it was determined that there were more zero counts of fish caught than we would expect to see if responses were coming from a Poisson distribution with $\lambda = 21.5$.

"True zeroes" would be those park visitors who will always report catching zero fish, because they never fish. Perhaps they are vegans, or have a degree in marine biology and know that fish are friends, not food. A zero-inflated Poisson model could estimate $\alpha$, the proportion of "true zeroes".

## BYSH 4.15.2 Guided Exercise 1 (Elephant Mating)

__How does age affect male elephant mating patterns? An article by Poole (1989) investigated whether mating success in male elephants increases with age and whether there is a peak age for mating success. To address this question, the research team followed 41 elephants for one year and recorded both their ages and their number of matings. The data is found in elephant.csv, and relevant R code can be found under elephantMating.R.__
 
__The variables are:__  
__MATINGS: the number of matings in a given year__  
__AGE: the age of the elephant in years.__  

```{r}
matings <- read.csv(paste("https://github.com/broadenyourstatisticalhorizons/bysh_book/", "raw/master/data/elephant.csv", sep=""))
```

__(f) Are the number of matings significantly related to age? Test with __

```{r}
matings.fit <- glm(MATINGS ~ AGE, family=poisson, data=matings)
matings.fit.sum <- summary(matings.fit)
```

*i. a Wald test*

```{r}
# Grab estimate and standard error of estimate
age.slope <- matings.fit.sum$coefficients[[2,1]]
age.se <- matings.fit.sum$coefficients[[2,2]]

# Calculate Wald test statistic
wald.test.stat <- age.slope / age.se
print(wald.test.stat)

# Compare test statistic to standard normal distribution
# using 2-sided Z test
wald.test.p <- 2 * pnorm(abs(wald.test.stat), lower.tail=FALSE)
print(wald.test.p)
```

With a p-value of $`r wald.test.p`$, the Wald test concludes that the number of matings is significantly related to age.

*ii. a drop in deviance test*

```{r}
# Create a null model to compare to
null.model <- glm(MATINGS ~ 1, family=poisson, data=matings)

# Calculate the drop in deviance going from the null model
# to the linear model (lower deviance indicates a better fit).
drop.in.dev <- null.model$deviance - matings.fit$deviance
print(drop.in.dev)

# Calculate the change in degrees of freedom going from
# the null model to the linear model.
diff.in.df <- null.model$df.residual - matings.fit$df.residual
print(diff.in.df)

# Compute the p-value for this drop in deviance test
# by comparing the deviance drop to a chi-squared
# distribution.
p.value <- pchisq(drop.in.dev, diff.in.df, lower.tail=FALSE)
print(p.value)
```

With a p-value of $`r p.value`$, the drop in deviance test concludes that the linear model is significantly better than the null model, and so number of matings is significantly related to age.

__(g) Add a quadratic term in AGE to determine whether there is a maximum age for the number of matings for elephants. Is a quadratic model preferred to a linear model? To investigate this question, use __

```{r}
matings.quad.fit <- glm(MATINGS ~ poly(AGE, 2), family=poisson, data=matings)
matings.quad.fit.sum <- summary(matings.quad.fit)
print(matings.quad.fit$coefficients)
```

The fit model is $log(mean Matings) = 0.8759 + 2.9690*Age - 0.2347*Age^2$, which has a maximum at $Age = 6.325$. The expected number of matings at this maximum is $e^{10.27} = `r exp(10.27)`$ matings per year. This is clearly an unreasonable number, given that the maximum observed number of matings was 9. Did I make a mistake somehow? Perhaps the coefficients of poly are not what I think they are.

Now let's examine if there is evidence that we should prefer a quadratic model over a linear one.

*i. a Wald test*

```{r}
# Grab estimate and standard error of estimate
age.sq.slope <- matings.quad.fit.sum$coefficients[[3,1]]
age.sq.se <- matings.quad.fit.sum$coefficients[[3,2]]

# Calculate Wald test statistic
wald.test.stat <- age.sq.slope / age.sq.se
print(wald.test.stat)

# Compare test statistic to standard normal distribution
# using 2-sided Z test
wald.test.p <- 2 * pnorm(abs(wald.test.stat), lower.tail=FALSE)
print(wald.test.p)
```

With a p-value of $`r wald.test.p`$, the Wald test concludes that there is no evidence of a relationship between number of matings and the quadratic age variable.

*ii. a drop in deviance test*

```{r}
# Calculate the drop in deviance going from the linear model
# to the quadratic model (lower deviance indicates a better fit).
drop.in.dev <- matings.fit$deviance - matings.quad.fit$deviance
print(drop.in.dev)

# Calculate the change in degrees of freedom going from
# the ljinear model to the quadratic model.
diff.in.df <- matings.fit$df.residual - matings.quad.fit$df.residual
print(diff.in.df)

# Compute the p-value for this drop in deviance test
# by comparing the deviance drop to a chi-squared
# distribution.
p.value <- pchisq(drop.in.dev, diff.in.df, lower.tail=FALSE)
print(p.value)
```

With a p-value of $`r p.value`$, the drop in deviance test concludes that there is no evidence of a relationship between number of matings and the quadratic age variable.

__(h) What can we say about the goodness of fit of the model with age as the sole predictor? Compare the residual deviance for the linear model to a $\chi^2$ distribution with the residual model degrees of freedom. __

```{r}
gof <- pchisq(matings.fit$deviance, matings.fit$df.residual, lower.tail=FALSE)
print(gof)
```

We can calculate the goodness of fit by testing the null hypothesis that our observed data came from the modelled Poisson distribution. The p-value of $`r gof`$ is above the standard 5% cut-off, and so we fail to reject the null hypothesis for the linear model.

## BYSH 4.15.2 Guided Exercise 3 (Bullfrogs)  

__*Big Bullfrog on the Pond*: Use the field observation bullfrog data bullfrogs.csv to determine whether there is convincing evidence that the number of mates is related to the size of the bullfrog.__

```{r q_4_15_2_3 load data}
bullfrogs <- read.csv(paste("https://github.com/broadenyourstatisticalhorizons/bysh_book/", "raw/master/data/bullfrogs.csv", sep=""))
```

__(a) Graph number of mates by size and comment.__

```{r}
bullfrogs %>% ggplot(aes(x=bodysize, y=mates)) + geom_point()
```

Seems to be a skewed distribution. The mean number of mates does seem to increase as size increases. Poisson regression may be appropriate.

__(b) Graph log(number of mates) by size and comment.__

```{r}
bullfrogs %>% ggplot(aes(x=bodysize, y=log(mates))) + geom_point()
```

How do we interpret the 0 counts which became negative infinity when the log transformation was applied? Anyway, this hardly looks like a linear relationship.

__(c) Write out the likelihood for the Poisson regression model.__

There are `r sum(bullfrogs$mates == 0)`, `r sum(bullfrogs$mates == 1)`, `r sum(bullfrogs$mates == 2)`, and `r sum(bullfrogs$mates == 3)` observations of 0, 1, 2, and 3 matings, respectively. Therefore the likelihood is:

$$
Likelihood = 18 * \frac{e^{-0}\lambda^0}{0!} * 15 * \frac{e^{-1}\lambda^1}{1!} * 3 * \frac{e^{-2}\lambda^2}{2!} * 2 * \frac{e^{-3}\lambda^3}{3!}
$$

__(d) Fit the Poisson regression model and interpret the coefficient. Provide a measure of uncertainty.__

```{r}
bf.fit <- glm(mates ~ bodysize, family=poisson, data=bullfrogs)
summary(bf.fit)

exp(bf.fit$coefficients)
exp(confint(bf.fit, 'bodysize'))
```

__(e) Conduct a goodness-of-fit test.__

```{r}
pchisq(bf.fit$deviance, bf.fit$df.residual, lower.tail=FALSE)
```

There's no evidence to reject the null hypothesis that our data is generated from this Poisson process.

__(f) Look at the residuals and comment.__

```{r}
list(deviances=summary(bf.fit)$deviance.resid, fitted.values=bf.fit$fitted.values) %>% as_tibble() %>% ggplot(aes(x=fitted.values, y=deviances)) + geom_point() + geom_line(y=0) + ggtitle("Deviance residuals vs fitted values")
```

Looking at the deviance residuals, we see two clear curves. This is a pattern, which is not good to see on a residuals plot. Maybe this pattern is related to our single predictor?

```{r}
list(deviances=summary(bf.fit)$deviance.resid, bodysize=bullfrogs$bodysize) %>% as_tibble() %>% ggplot(aes(x=bodysize, y=deviances)) + geom_point() + geom_line(y=0) + ggtitle("Deviance residuals vs Body Size")
```

Well, nope the pattern is still there and it's not clear how the predictor is related to it, if at all. I'm not sure how to explain this.
